\section{Introduction}

The deluge of huge data sets such as those provided by sensor
networks, online transactions, and petascale simulation provide 
exciting opportunities for data analytics.  
The scale of the data makes it increasingly difficult to process 
in a reasonable amount of time on isolated machines.
In the near future petascale and exascale simulation will make 
the involvement of secondary storage and disks impractical, driving
the need for infrastructures which provide in-situ analytics and
visualization capabilities~\cite{ma:in-site}.

Our experiences with existing tools for constructing dataflow workflows
for simulation, transformation, analysis and visualization were frustrating.

* tight coupling of language, runtime, and workflow methodology
* overly complex and difficult to deploy on petascale clusters or 
dynamic resources
* primarily targeted at post-processing

%This has lead to data flow systems emerging
%as the standard tool for solving research problems using these vast
%datasets.  In typical dataflow systems,
%runtimes~\cite{dean2008msd}~\cite{bialecki:hfr}~\cite{isard2007ddd}
%~\cite{streamit} and  define graphs of processes, the edges of the graphs
%representing pipes and their vertices representing computation on a
%system.  Within these runtimes a new class of
%languages~\cite{pike2005idp}~\cite{yu2008dsg}~\cite{olston2008pln} can
%be used by researchers to solve "pleasantly parallel" problems(problems where the individual elements of datasets are considered
%to be independent of any other element) more quickly without worrying
%about explicit concurrency.
%
%These languages provide automated control flow(typically matched
%to the architecture of the underlying runtime) and channels of
%communication between systems.  In existing systems, these workflows
%and the underlying computation are tightly linked, tying solutions
%to a particular runtime, workflow and language.  This creates
%difficulties for analytics researchers who wish to draw upon tools
%written in many different languages or runtimes which may be available
%on several different architectures or operating systems.

We observe that UNIX pipes were designed to get around many of these
incompatibilities, allowing developers to hook together tools written
in different languages and runtimes in ad-hoc fashions.  This allowed
tool developers to focus on doing one thing well, and enabled code
portability and reuse in ways not originally conceived by the tool
authors.  The UNIX shell incorporated a model for tersely composing
these smaller tools in pipelines (e.g. 'sort $|$ uniq -c'), creating
coherent workflow to solve more complicated problems quickly.  Tools
read from standard input and wrote to standard output, allowing
programs to work together in streams \emph{with no explicit knowledge
of this chaining built into the program itself}.

One to one pipelines such as those used by a typical UNIX shell,
can not be trivially mapped to streaming workflows which incorporate
one-to-many, many-to-many, and many-to-one data flows.  Additionally,
typical UNIX pipeline tools write data according to buffer boundaries
instead of record boundaries.  As \cite{pike2005idp} notes dataflow
systems need to be able to cleanly separate input streams into
records and then show that the order of these records is independent.
By separating input and output into discrete unordered records data
can be easily distributed and coalesced.

To address these issues we have implemented a prototype shell, which
we call PUSH, using dataflow principles and incorporating extended
pipeline operators to establish distributed workflows ---potentially
running on clusters of machines--- and correlate results.  
%Our
%implementation is based on extending an existing shell, MASH\cite{mashman},
%from which we inherited a rich interpreted scripting language.  It
%treats variables as lists of strings and has no native handling for
%any other data type.  Integer expression handling and other facilities
%are provided by shell commands.  It has native regular expression
%support and it has a novel ability to do declarative shell programming
%through a make like syntax incorporated in the shell itself.
%
%We currently have a working prototype of the PUSH shell, which we
%can use to target local distributed clusters, dynamic clusters built
%using Amazon's EC2 cloud, and large scale clusters such as a Blue
%Gene running the kittyhawk infrastructure.  We are currently in the
%process of evaluating and optimizing performance for a variety of
%application types.
%
%the RC shell\cite{rcpaper} to easier integration into traditional unix
%systems like Linux. This version is simplified and closer to the
%bourne shell. The explicit goal of the new version of Push is
%integration with the Unified Execution Model(UEM)\cite{van-unified} which will
%allow the transparent distribution of processes and the connection
%of their communication channels between machines transparently.
%This work is taking place as part of the HARE project\cite{van2008holistic} 

This paper is organized as follows. The next section 
covers our core design elements of the PUSH shell and the distributed
infrastructure we use to deploy PUSH workflows on systems ranging from
single nodes to bluegene.  Section 3 will discuss some of the implementation
details and experiences of our initial prototype.  In Section 4 we will 
evalute the overhead of our infrastructure and in section 5 we will discuss
the results and explore opportunities for improvement in both the design
and implementation of our approach.

