#!/bin/rc
# 
# Multipipe Regression
#

echo '== Multipipe Regression =='

#
# Parameters
#
MPIPELOG=mpipefs.log
TESTDIR=.test
DEBUG_LEVEL=0

#
# Cleanup Previous Instances
#
fn cleanup {
	echo Cleaning up previous runs...
	unmount /n/mpipetest > /dev/null >[2] /dev/null
	rm -f /srv/mpipe
	#kill mpipefs | rc
}

#
# Startup mpipefs (maybe with debug evel specified by $1)
#
fn startup {
	echo Starting mpipefs....
	if(~ $#* 0) {
		mpipefs >[2] $MPIPELOG 
	}
	if not {
		mpipefs -D -v $1 >[2] $MPIPELOG 	# CHATTY
		DEBUG_LEVEL=$1
	}
}

#
# Setup a ramfs
#
fn testdir {
	mkdir -p $TESTDIR
}

#
# The test number names are generated and cached for later use.
#
TESTNUM=( 1 )

#
# Enumerate the test numbers
#
fn enum_tests {
	TESTNUM=`{awk 'BEGIN     {
               for (i = 1; i <= '$1'; i++) printf "%d ", i
               exit }'}
	#`# shut up the code coloring bug...
}

#
# Check to make sure that the files are ready to read and not just
# opened or hung.
#
APID=() # keep a list of child PID's
HEADER=0
fn check_ready {
#	if(! ~ $DEBUG_LEVEL 0) {
#		if(~ $HEADER 0) {
#			echo
#			echo '    Checking readyness'
#			HEADER=1
#		}
#	}

	# FIXME: should we terminate after some number of tries, or
	# just keep spinning...
	DONE=0
	while (~ $DONE 0) {
		DONE=1
		for(i in $APID) {
	    		STATE=`{cat /proc/$i/status | sed 's%cat[ ]*[^ ]*[ ]*%%
				s%  *.* (.*)%%'}
			#`# turn off code coloring snafu

			# sanity check
			if(! ~ $status '') {
				exit $status 
			}

	    		# check if it is not ready to read
			if(! ~ $STATE 'Pread') {
#				if(! ~ $DEBUG_LEVEL 0) 
#	    				echo '        ' $i $STATE
				DONE=0
			}
		}
       	}
}

#
# Create a number of tests
#
fn create_tests {
	enum_tests $1

	HEADER=0 # reset the readness header 

	# create empty test files 
	for(i in $TESTNUM) {
	    echo > $TESTDIR/test$i
	}
}

#
# Compare the output
#
fn cmp_tests {
	enum_tests $1

	HEADER=0 # reset the readness header 

	# verify results
	for(i in $TESTNUM) {
	    if(! cmp -s $TESTDIR/test $TESTDIR/test$i) {
	        echo
		echo '	'FAILED: test$i not equal to test
		exit 'cmp_tests: test$i failed for: ' $2
	    }
	}
}

#
# Naming pipe test
#

fn named {
	echo -n Testing name parameter...

	mount /srv/mpipe /n/mpipetest test
	if(! test -e /n/mpipetest/test) {
		echo FAILED!
		exit 'named: test failed'
	}

	echo Success!	
	# cleanup
	unmount /n/mpipetest
}


#
# Simple Pipe Test
#

fn simplepipe {
	echo -n Testing simple pipe operation...

	# initialize files
	echo Hello Squidboy > $TESTDIR/test
	create_tests 1

	mount /srv/mpipe /n/mpipetest
	cat $TESTDIR/test > /n/mpipetest/data &
	cat /n/mpipetest/data > $TESTDIR/test1

	# verify results
	cmp_tests 1 'simplepipe'

	echo Success!
	# cleanup
	rm -rf $TESTDIR/*
}

#
# Multi Pipe test
#

fn multipipe {
	echo -n Testing multipipe messages...

	NUM_TESTS=9
	NUM_PASSED=3

	# initialize test files
	create_tests $NUM_TESTS

	# initialize files
	mount /srv/mpipe /n/mpipetest

	# spawn a number of threads which copy the mpipe data the
	# tests.  It waits for stuff to be written to
	# /n/mpipetest/data
	APID=()
	for(i in $TESTNUM) {
	    cat /n/mpipetest/data > $TESTDIR/test$i &
	    APID=( $APID $apid )

	    # wait for each reader to become ready before creating the
	    # next.  Note: this is not the most efficient way of doing
	    # this as it checks all of them, but the check is already
	    # written...

	    # FIXME: the above does not work to force determinis.  We
	    # should move this outsize later
	    check_ready 
	}

	# No need to check to make sure all the readers are ready,
	# because we did it in the loop.

	# write to two and only two readers
	if(~ $DEBUG_LEVEL 0) {
		mp-writer -n $NUM_PASSED -s 8192 /n/mpipetest/data
	}
	if not {
		mp-writer -D -n $NUM_PASSED -s 8192 /n/mpipetest/data
	}

	# wait for children to finish
	wait

	# make a list of all tests that meet the criteria
	T=()
	for(i in $TESTNUM) {
	    LST=`{ls -l $TESTDIR/test$i | sed 's%[^ ]* [^ ]* [^ ]* [^ ]* [^ ]* %%' | sed 's% .*%%'} #`#
	    #LST2=`{echo $LST1 | sed 's/.* \([0-9]*\).* .*/\1/'} #`#

	    if(! ~ $LST 0) {
		T=($T $LST)
	    }
	}

#	if(! ~ $DEBUG_LEVEL 0)
#		echo 'Number of tests: '$#T

	# make sure the number of tests that passed was that expected
	if(! ~ $#T $NUM_PASSED) {
	    echo 'FAILED (multipipe): more than one file has data in longmsg'
	    exit 'multipipe'
	}

#	# two, and only two, files should have any data in it
#	FILLED=0
#	for(i in $TESTNUM) {
#	    LST=`{ls -s $TESTDIR/test$i | sed 's% .*%%'} #`#
#	    if(! ~ $LST 0) {
#		 echo '   Test'$i' has data'
#		if(! ~ $FILLED 0 && ! ~ $FILLED 1 ) {
#		    echo 'FAILED: more than one file has data in longmsg'
#		    exit 'multipipe'
#		}
#		FILLED=1
#	    }
#	}

	# FIXME: the determinish test fails.  If you want to determine
	# which of the pipes get written to we will have to
	# investigate this seperately.

	# now check to make sure that the writing was
	# deterministically set
	#if(~ `{ls -s $TESTDIR/test1 | sed 's% .*%%'} 0 
	#  || `{ls -s $TESTDIR/test2 | sed 's% .*%%'} 0 ) {
	#    echo 'FAILED: the multipipe write was not deterministic'
	#    exit 'multipipe'
	#}

	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

fn enum {
	echo -n Testing enumerated messages...

	# initialize files
	create_tests 2

	mount /srv/mpipe /n/mpipetest '-e 2'

	# spawn a number of threads.  One of them will get data from
	# mp-writer.
 	APID=()
	for(i in $TESTNUM) {
	    cat /n/mpipetest/data > $TESTDIR/test$i &
	    APID=( $APID $apid )
	}

	# wait for test files to become ready
	check_ready

	# write some data to one, and only one, of them
	mp-writer -e 1 -n 5 -s 8192 /n/mpipetest/data	

	# wait for children to be done...
	wait

	# only one of the files should have any data in it
	FILLED=0
	for(i in $TESTNUM) {
	    LST=`{ls -s $TESTDIR/test$i | sed 's% .*%%'} #`#
	    if(! ~ $LST 0) {
		if(! ~ $FILLED 0) {
		    echo 'FAILED: more than one file has data in enum'
		    exit 'enum'
		}
	    }
	}

	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

# TODO: 8192 is not long enough, but anything above 64k breaks
fn longmsg {
	echo -n Testing long messages...

	# initialize files
	create_tests 2

	mount /srv/mpipe /n/mpipetest

	# spawn a number of threads.  One of them will get data from
	# mp-writer.
 	APID=()
	for(i in $TESTNUM) {
	    cat /n/mpipetest/data > $TESTDIR/test$i &
	    APID=( $APID $apid )
	}

	# wait for test files to become ready
	check_ready

	# write a data block that is WAY TO big...
	mp-writer -e 1 -n 1 -s 131072 /n/mpipetest/data	

	# wait for children to be done...
	wait

	# only one of the files should have any data in it
	FILLED=0
	for(i in $TESTNUM) {
	    LST=`{ls -s $TESTDIR/test$i | sed 's% .*%%'} #`#
	    if(! ~ $LST 0) {
		if(! ~ $FILLED 0) {
		    echo 'FAILED: more than one file has data in longmsg'
		    exit 'longmsg'
		}
	    }
	}

	echo Success!
	# cleanup
	rm -rf $TESTDIR/*
}

# Broadcast test
#
fn bcast {
	echo -n Testing with broadcast...

	NUM_TESTS=9
	NUM_PASSED=3

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test
	create_tests $NUM_TESTS

	# accomplish the test
	mount /srv/mpipe /n/mpipetest -b

	# spawn a number of threads which copy the mpipe data the
	# tests.  It waits for stuff to be written to
	# /n/mpipetest/data
	APID=()
	for(i in $TESTNUM) {
	    cat /n/mpipetest/data > $TESTDIR/test$i &
	    APID=( $APID $apid )
	}

	# check to make sure all the readers are ready.  I am not sure
	# this is strictly necessary
	check_ready 

	cat $TESTDIR/test > /n/mpipetest/data

	# we have to wait for all the children to finish their reads.

	# FIXME: look at checking the status of the read device again.
	# Supposedly it terminates immediately, but the children are
	# not finished.
	wait

	# FIXME: Umount of the multipipe does ***not*** flush readers.
	# Should it? -- no, but think about erroring to the writer
	unmount /n/mpipetest

	# FIXME: do not hangup until unmount (a mode for mpipefs)

	# verify results
	cmp_tests $NUM_TESTS 'bcast'

	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

#
# splicefrom test
#
fn splicefrom {
	echo -n Testing splicefrom...

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test
	create_tests 1

	# accomplish the test
	mount /srv/mpipe /n/mpipetest


	cat /n/mpipetest/data > $TESTDIR/test1 &
	APID=( $apid )

	# wait for test files to become ready
	check_ready

	mp-writer -i $TESTDIR/test /n/mpipetest/data
	
	wait 

	# verify results
	cmp_tests 1
	
	echo Success!
	unmount /n/mpipetest

	# cleanup
	rm -rf $TESTDIR/*
}

#
# splicefrom broadcast test
#
fn splicefrombcast {
	echo -n Testing splicefrom with broadcast ...

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test

	# create empty test files
	create_tests 20

	# accomplish the test
	mount /srv/mpipe /n/mpipetest -b

	# spawn a number of threads which copy the mpipe data the
	# tests.  It waits for stuff to be written to
	# /n/mpipetest/data
	APID=()
	for(i in $TESTNUM) {
	    cat /n/mpipetest/data > $TESTDIR/test$i &
	    APID=( $APID $apid )
	}

	# make sure that everything is ready
	check_ready # poor mans synchronization

	mp-writer -i $TESTDIR/test /n/mpipetest/data
	
	# FIXME: check_ready # verify that the state of the write is done
	wait

	# verify results
	cmp_tests 20

	echo Success!
	unmount /n/mpipetest

	# cleanup
	rm -rf $TESTDIR/*
}

#
# spliceto test
#
fn spliceto {
	echo -n Testing spliceto...

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test
	create_tests 1

	# accomplish the test
	mount /srv/mpipe /n/mpipetest
	mp-writer -o $TESTDIR/test1 /n/mpipetest/data

	cat $TESTDIR/test > /n/mpipetest/data

	unmount /n/mpipetest
	
	# verify results
	cmp_tests 1

	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

#
# splice to chain to tests problem
# experienced using multinode gangfs
#

fn splicetochain {
	echo -n Testing spliceto chains...

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test
	create_tests 1

	# accomplish the test
	# stage0 and stage1 feeds stage2 which feeds stage3
	mount /srv/mpipe /n/stage0 s0
	mount /srv/mpipe /n/stage1 s1
	mount /srv/mpipe /n/stage2 s2
	mount /srv/mpipe /n/stage3 s3
	mp-writer -o /n/stage2/s2 /n/stage0/s0
	mp-writer -o /n/stage2/s2 /n/stage1/s1
	mp-writer -o /n/stage3/s3 /n/stage2/s2
	mp-writer -o $TESTDIR/test1 /n/stage3/s3
	echo one > /n/stage0/s0
	echo two > /n/stage1/s1
	
	unmount /n/stage0
	unmount /n/stage1
	unmount /n/stage2
	unmount /n/stage3
	
	# verify results
	echo one > $TESTDIR/test2
	echo two >> $TESTDIR/test2
	if(! cmp -s $TESTDIR/test2 $TESTDIR/test1) {
		echo FAILED: test1 not equal to test2
		exit 'splicetochain: failed'
	}
	
	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

#
# Broadcast spliceto test
#
fn splicetobcast {
	echo -n Testing spliceto with broadcast...

	# initialize test files
	echo Hello Squidboy > $TESTDIR/test
	create_tests 20

	# accomplish the test
	mount /srv/mpipe /n/mpipetest -b

	# create a batch of writers dumping from the multipipe to an
	# output stream.  Note: mp-writer sends a control message to
	# mpipefs which spawns another version of itself, however,
	# when mp-writer returns it is ready so there is no reason to
	# wait or check its ready status.
	enum_tests 20
	for(i in $TESTNUM) {
	    mp-writer -o $TESTDIR/test$i /n/mpipetest/data 
	}

	# broadcast the message.
	cat $TESTDIR/test > /n/mpipetest/data

	# FIXME: try another check for all writers?
	wait # needs to happen before the unmount because it does not flush 

	# FIXE: does not flush?
	unmount /n/mpipetest
	
	# verify results
	cmp_tests 20

	echo Success!

	# cleanup
	rm -rf $TESTDIR/*
}

# Setup
cleanup
startup $*
testdir

# Tests
named
simplepipe
longmsg
#  TODO: will this really happen deterministicly?
multipipe  #<--- FAILS sometimes due to non-determinsm
enum 
bcast
splicefrom
spliceto
splicetobcast
splicefrombcast
splicetochain

# Cleanup
rm -f $TESTDIR
cleanup

